{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3eb84e3-77c4-4fed-829e-1af31672d559",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f71784a-77d7-4a38-bd05-28505dcf7c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import motornet as mn\n",
    "from motornet.effector import RigidTendonArm26\n",
    "from motornet.muscle import MujocoHillMuscle\n",
    "from motornet.environment import RandomTargetReach\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983dd5ec-d931-4922-b934-be5f429fe40e",
   "metadata": {},
   "source": [
    "### The arm26 effector and a MotorNet random-reach environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "885d1931-014f-4d4e-9604-c2ecc35a03e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs shape: torch.Size([1, 16])\n",
      "goal (target): tensor([[-0.2529,  0.5768]])\n",
      "fingertip: tensor([[-0.1736,  0.5117]])\n",
      "muscle state shape: torch.Size([1, 7, 6])\n",
      "proprioception sample: tensor([0.8958, 1.1298, 1.0077, 0.7976, 0.8120, 0.8185, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n"
     ]
    }
   ],
   "source": [
    "# arm26 effector\n",
    "muscle = MujocoHillMuscle()\n",
    "arm26 = RigidTendonArm26(muscle=muscle)\n",
    "\n",
    "# random-reach environment\n",
    "env = RandomTargetReach(\n",
    "    effector=arm26,\n",
    "    name=\"arm26_random_reach\",\n",
    "    max_ep_duration=5.0,     # 5 s - like Codol\n",
    "    action_frame_stacking=0,\n",
    "    proprioception_delay=arm26.dt,\n",
    "    vision_delay=arm26.dt,\n",
    "    proprioception_noise=0.0,\n",
    "    vision_noise=0.0,\n",
    "    obs_noise=0.0,\n",
    "    action_noise=0.0,\n",
    ")\n",
    "\n",
    "obs, info = env.reset()\n",
    "print(\"obs shape:\", obs.shape)# obs shape: torch.Size([1, 16])\n",
    "# 2 (goal) + 2 (fingertip) + 6 (muscle lengths) + 6 (muscle velocities)\n",
    "print(\"goal (target):\", env.goal)\n",
    "print(\"fingertip:\", env.states[\"fingertip\"])\n",
    "print(\"muscle state shape:\", env.states[\"muscle\"].shape)\n",
    "print(\"proprioception sample:\", env.get_proprioception()[0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94ee4cd3-7f81-4ee9-8095-877826ec436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final fingertip: tensor([[-0.1698,  0.4403]])\n"
     ]
    }
   ],
   "source": [
    "# This cell steps the environment forward using random muscle activations for a few \n",
    "# timesteps to confirm that the arm moves and the state updates correctly.\n",
    "\n",
    "for t in range(10):\n",
    "    action = torch.rand(1, arm26.n_muscles)  # random actions\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    if terminated:\n",
    "        break\n",
    "\n",
    "print(\"final fingertip:\", env.states[\"fingertip\"])\n",
    "\n",
    "# RESULTS :\n",
    "# the arm responds to the random muscle activations,\n",
    "# the state updates over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d3f082-6239-43b9-bba8-cbb96c3a4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodolObsWrapper:\n",
    "    \"\"\"\n",
    "    Wraps a MotorNet RandomTargetReach env and produces observations as described in the Codol paper:\n",
    "    [go, endpoint, start, target, muscle_length(6), muscle_velocity(6)]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_env, go_delay_steps=0):\n",
    "        self.env = base_env\n",
    "        self.go_delay_steps = go_delay_steps\n",
    "        self.t = 0\n",
    "        self.start_pos = None   # fingertip at t=0\n",
    "\n",
    "    def reset(self):\n",
    "        obs, info = self.env.reset()\n",
    "        self.t = 0\n",
    "        # store starting fingertip position (batch 1)\n",
    "        self.start_pos = self.env.states[\"fingertip\"].clone()  # [1,2]\n",
    "        return self._build_policy_obs()\n",
    "\n",
    "    def _split_proprio(self):\n",
    "        \"\"\"\n",
    "        MotorNet proprioception = [len(6), vel(6)] normalized, shape [1,12]\n",
    "        \"\"\"\n",
    "        proprio = self.env.get_proprioception()  # [1,12]\n",
    "        lengths = proprio[:, :6]\n",
    "        vels    = proprio[:, 6:]\n",
    "        return lengths, vels\n",
    "\n",
    "    def _build_policy_obs(self):\n",
    "        # go cue: 0 until go_delay_steps, then 1\n",
    "        go_val = 1.0 if self.t >= self.go_delay_steps else 0.0\n",
    "        go = torch.tensor([[go_val]], dtype=torch.float32)\n",
    "\n",
    "        endpoint = self.env.states[\"fingertip\"]        # [1,2]\n",
    "        start    = self.start_pos                      # [1,2]\n",
    "        target   = self.env.goal                       # [1,2]\n",
    "        lengths, vels = self._split_proprio()          # [1,6], [1,6]\n",
    "\n",
    "        policy_obs = torch.cat(\n",
    "            [go, endpoint, start, target, lengths, vels],\n",
    "            dim=1\n",
    "        )  # shape [1, 19]\n",
    "\n",
    "        return policy_obs\n",
    "\n",
    "    def step(self, action):\n",
    "        self.t += 1\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        policy_obs = self._build_policy_obs()\n",
    "        done = terminated or truncated\n",
    "        return policy_obs, reward, done, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeafca90-6bbc-4226-9911-f632c18fe37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs shape: torch.Size([1, 19])\n",
      "steps run: 20\n",
      "last obs example: tensor([[ 1.0000,  0.0235,  0.1714,  0.0633,  0.3937,  0.2432,  0.5737,  1.1875,\n",
      "          0.8505,  0.5455,  1.0616,  0.6974,  0.7185,  0.0000,  0.0000,  0.0154,\n",
      "         -0.0060,  0.0203, -0.0059]])\n"
     ]
    }
   ],
   "source": [
    "wrapped = CodolObsWrapper(env, go_delay_steps=0)\n",
    "\n",
    "obs = wrapped.reset()\n",
    "print(\"obs shape:\", obs.shape)   # torch.Size([1, 19])\n",
    "# [go, endpoint(2), start(2), target(2), lengths(6), velocities(6)]\n",
    "\n",
    "rewards = []\n",
    "for step in range(20):\n",
    "    action = torch.rand(1, env.effector.n_muscles)\n",
    "    obs, reward, done, info = wrapped.step(action)\n",
    "    rewards.append(reward)\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print(\"steps run:\", len(rewards))\n",
    "print(\"last obs example:\", obs)\n",
    "\n",
    "# This cell tests the CodolObsWrapper by running a short rollout with random actions, \n",
    "# confirming the wrapped environment steps correctly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MotorNet (RL)",
   "language": "python",
   "name": "motornet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
